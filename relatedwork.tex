\section{related work}
	% -related work
	% 	-LOS vs NLOS (SNR實驗)
	% 	-communication not only localization
	% 	-luxapose
	% -rolling shutter相關知識
	% 	-operation and channel model
	% 	-特色:跟perspective, orientation無關

% \subsection{Camera-received VLC}
\subsection{Screen-to-camera Communications}
A number of prior works~\cite{perli2010pixnet,hao2012cobra,hu2013lightsync} utilized cameras as the receiver to implement one-way communication links. Those works utilized a LCD screen as the transmitter. The main benefit of this approach is that both the ability to display different colors and the high resolution of the LCD could be fully exploited, to improve the data rate.

PixNet \cite{perli2010pixnet} utilized the large quantity of pixels on a LCD to form OFDM symbols to transmit data to the camera receiver, and the implemented prototype has perspective correction ability.

COBRA \cite{hao2012cobra} proposed a similar approach that uses pixels as as barcodes and utilized the color information of pixels to achieve higher signal to noise ratio.
These works, however, did not solve the problems raised by the unsynchronized transmitter and receiver pair. The presented solution is to repeat the same packet transmission twice in order to guarantee the reception of all signal segments.

LightSync \cite{hu2013lightsync} introduces inter-frame erasure coding and line sequence number to reduce the high packet error rate due to synchronization issues. The approach also actively filters out rolling-shutter effects.

VRCodes (NewsFlash) \cite{vrcodes} takes advantage of the rolling shutter effect to decode visual tags displayed on LCDs. The tags use multiple pixels of different colors, modulated at up to 120Hz to transmit data. The technology exploits the "flicker-fusion threshold" of the human eye to blend the tags into the background by rapidly flashing complimentary hues of color, still visible to a rolling shutter camera. This work suggests how different color channels could be used to increase data throughput, while still keeping transmissions imperceptible to humans.

Visual MIMO \cite{visualmimo1, visualmimo2, visualmimo3} is a method that uses any light-emitting spatial array as the transmitter and uses ordinary cameras as the receivers.
It proposes a photometric modeling for hidden imagery and can realize a dual use of the electronic display: to display an image for human observation while simultaneously transmitting hidden bits for decoding by a camera.

Compared to these works, we proposed to use only a single LED light as the transmitter and a commonly available CMOS camera as the receiver, and many design considerations are not the same as these prior research works utilizing multiple optical transmitting sources.

\subsection{Single-LED-to-camera Communications}
Three works \cite{roberts2013undersampled, danakis2012using,landmark} have previously investigated how to implement single-LED-to-camera communication links. 
In~\cite{roberts2013undersampled}, the author proposes undersampled frequency shift OOK (UFSOOK), which allows the use of a high signal frequency while the modulation can still be decoded by a common camera with 30 fps (frame rate per second). The scheme is compatible to both global shutter and rolling shutter cameras, but the maximum achievable data rate is only half of the frame rate per light source.

In \cite{danakis2012using}, the authors utilized rolling shutter sampling to encode data with Manchester coding at high symbol rate, and was the first work to take advantage of the rolling shutter to implement CamCom. 
However, the implementation exhibits a high packet drop rate due to the long processing time of the decoder application per frame and lack of considerations for synchronization issues. Thus, the reception is not continuous and some frames are inevitably lost. The transmitter then needs to send signal.
In addition, the transmitting light needs to illuminate the entire image for the receiver to demodulate the transmission.We can achieve a data rate much higher than 50\% of the frame rate per light source, and have designs to address the issues caused by the exposure operation of the camera and unsynchronized nature of the communication link.
A further drawback in this work is that the modulated signal can produce a human perceivable flicker from transmitting LED. The authors alleviate this by imposing a DC bias on the signal, which in turn decreases its dynamic range and SNR at the receiver. This makes the scheme require significantly brighter lights and more complex driving hardware than our proposed approach.

In \cite{landmark}, the author used binary frequency shift keying (BFSK) of a high frequency PWM signal to encode data that can be used as localization landmarks. On the receiver side, they exploited rolling shutter camera sensors to detect high-frequency changes in the intensity of light reflected off surfaces, which is indirect line-of-sight of the camera. The data rate is only 1.25 bytes per second (the authors claimed that it is fast enough to send an ID code) while in our work there is a need to increase the data rate to communicate rather than just perform localization. To detect the transmitting frequency, they used 1-D fast Fourier transform. However, we have tried the FFT method before and it usually requires a threshold to eliminate the noise. It is hard to have a general threshold which can be adopted in different environments. For the receiver which is unsynchronized with the transmitter, they proposed a sliding window approach where they first stitch all of the captured frames together into a single, long image. Then they can detect the frequency by sliding the window and locating the window position corresponding to the highest power. However, we can stitch the images only if the light is full of whole image (for example, reflected from the surface). Moreover, if there is a symbol loss between the two frames, then the result of stitching images would likely be inaccurate. In our work, we use additional schemes to address these problems.